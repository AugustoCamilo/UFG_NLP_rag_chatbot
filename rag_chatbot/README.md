# Solu√ß√£o de Chatbot RAG com Gemini, Re-Ranking Avan√ßado e Su√≠te de Avalia√ß√£o de M√©tricas

Este projeto implementa uma aplica√ß√£o web completa de um chatbot RAG (Gera√ß√£o Aumentada por Recupera√ß√£o). Ele permite que os usu√°rios conversem sobre um conjunto de documentos PDF personalizados, fornecendo respostas contextuais e precisas, com a capacidade de coletar feedback sobre as respostas geradas.

O diferencial desta solu√ß√£o √© a sua **Su√≠te de Avalia√ß√£o e Auditoria**, um conjunto de ferramentas web dedicadas que permitem a uma equipe de avaliadores testar, medir (com m√©tricas como **Hit Rate**, **MRR** e **Precis√£o@K**), e consolidar relat√≥rios de performance (via Import/Export XML), criando um ciclo de melhoria cont√≠nua (CI/CD) para a qualidade do RAG.

A solu√ß√£o utiliza uma arquitetura moderna que combina:

  * Um LLM de alta performance (Google Gemini).
  * Um banco de dados vetorial local (ChromaDB) para armazenamento de embeddings.
  * Um pipeline de recupera√ß√£o sofisticado de dois est√°gios (Recall + Re-ranking) para maximizar a relev√¢ncia.
  * Um banco de dados SQLite para persistir o hist√≥rico das conversas, feedbacks e **dados de avalia√ß√£o de m√©tricas**.

## Principais Funcionalidades

  * **Ingest√£o de Dados Otimizada:** Processa arquivos PDF (`PyMuPDFLoader`), limpa rodap√©s customiz√°veis (Regex) e divide em *chunks* otimizados (`RecursiveCharacterTextSplitter`).
  * **Armazenamento Vetorial:** Utiliza o **ChromaDB** para criar e persistir um banco de dados de embeddings localmente.
  * **Recupera√ß√£o H√≠brida (2-Est√°gios):**
    1.  **Recall (Busca Vetorial R√°pida):** Usa um modelo Bi-Encoder (`all-MiniLM-L6-v2`) para encontrar rapidamente os `SEARCH_K_RAW` (padr√£o 20) documentos semanticamente similares.
    2.  **Precision (Re-Ranking Inteligente):** Reavalia os resultados do Recall usando um modelo CrossEncoder (`cross-encoder/ms-marco-MiniLM-L6-v2`) para reorden√°-los com base na relev√¢ncia e selecionar os `SEARCH_K_FINAL` (padr√£o 3) documentos mais relevantes.
  * **Gera√ß√£o de Resposta:** Utiliza a API do **Google Gemini** para gerar respostas fluentes, baseando-se no contexto recuperado e no hist√≥rico da conversa.
  * **Interface Web (`app.py`):** Interface de chat principal para o usu√°rio final, constru√≠da com **Streamlit**.
  * **Mem√≥ria e Feedback:** Armazena o hist√≥rico completo da conversa (incluindo m√©tricas de performance e tokens) e o feedback do usu√°rio (üëç/üëé) no banco **SQLite**.

### Su√≠te de Avalia√ß√£o e Auditoria

O sistema inclui tr√™s aplica√ß√µes web independentes para valida√ß√£o e auditoria:

1.  **`validate_vector_db.py` (Coleta de Avalia√ß√£o):**

      * Uma interface para o "Avaliador Humano" testar a performance do retriever (Modo Vetorial vs. Modo Re-Ranking).
      * O avaliador marca os chunks relevantes (para Hit Rate/Precis√£o) e o melhor chunk (para MRR).
      * **Salva** os resultados da avalia√ß√£o (queries, chunks, scores, e m√©tricas calculadas) no banco de dados SQLite (`validation_runs`, `validation_retrieved_chunks`).

2.  **`validate_evaluation.py` (Dashboard de M√©tricas):**

      * A ferramenta central de *an√°lise* que **l√™** os dados de avalia√ß√£o salvos.
      * **Resumo de M√©tricas:** Apresenta um dashboard que compara `vector_only` vs. `reranked` lado a lado, com as m√©dias de **Hit Rate**, **MRR** e **Precis√£o@K**.
      * **Lista Detalhada:** Permite ver cada rodada de teste individualmente, com suas m√©tricas e chunks.
      * **Exportar/Importar XML:** Permite que equipes exportem seus resultados de avalia√ß√£o e importem os resultados de colegas, consolidando os dados. O sistema ignora duplicatas automaticamente durante a importa√ß√£o (baseado no timestamp).

3.  **`validate_history_db.py` (Auditoria de Produ√ß√£o):**

      * Um dashboard de "BI" que **l√™** o hist√≥rico de uso do `app.py` (tabelas `chat_history` e `feedback`).
      * Permite listar todas as sess√µes, ver transcri√ß√µes completas e auditar o feedback (üëç/üëé) dado pelos usu√°rios finais.

-----

## Arquitetura e Fluxo de Dados

O sistema √© modular, com depend√™ncias claras entre os scripts.

### 1\. Componentes Principais (Produ√ß√£o)

  * **`app.py` (Frontend)**
      * Renderiza a UI do chat e gerencia o `session_id`.
      * Depende de: `rag_chain.py` (para gerar respostas e salvar feedback).
  * **`rag_chain.py` (Backend L√≥gico)**
      * Orquestra o fluxo RAG (hist√≥rico, recupera√ß√£o, gera√ß√£o) usando LangGraph.
      * Depende de: `vector_retriever.py` (para buscar contexto), `database.py` (para ler/escrever hist√≥rico e feedback), `config.py` (para o LLM).
  * **`vector_retriever.py` (M√≥dulo de Recupera√ß√£o)**
      * Implementa a l√≥gica de Recall (Chroma) e Re-Ranking (CrossEncoder).
      * Depende de: `config.py` (para nomes de modelos e par√¢metros K), `/vector_db` (para ler o ChromaDB).
  * **`database.py` (Schema do Banco)**
      * Define a estrutura de *todas* as tabelas do SQLite (Produ√ß√£o e Avalia√ß√£o).
      * Depende de: `sqlite3`.
  * **`config.py` (Configura√ß√£o)**
      * Centraliza todos os caminhos, chaves de API e nomes de modelos.
      * N√£o tem depend√™ncias de outros m√≥dulos do projeto.

### 2\. Scripts de Ingest√£o e Ferramentas

  * **`ingest.py` (Ingest√£o)**
      * Script de linha de comando para popular o banco de vetores.
      * Depende de: `config.py` (para caminhos e modelos), `/docs` (l√™ PDFs), `/vector_db` (escreve/sobrescreve o ChromaDB).
  * **`validate_vector_db.py` (Coleta de Avalia√ß√£o)**
      * App Streamlit para *escrever* dados de avalia√ß√£o.
      * Depende de: `vector_retriever.py` (para rodar as buscas) e `database.py` (para salvar os resultados).
  * **`validate_evaluation.py` (Dashboard de M√©tricas)**
      * App Streamlit para *ler, analisar, exportar e importar* dados de avalia√ß√£o.
      * Depende de: `database.py` (para ler/escrever na tabela `validation_runs`).
  * **`validate_history_db.py` (Auditoria de Produ√ß√£o)**
      * App Streamlit para *ler* o hist√≥rico de produ√ß√£o.
      * Depende de: `database.py` (para ler as tabelas `chat_history` e `feedback`).

-----

## Tecnologias e Depend√™ncias

A solu√ß√£o utiliza as seguintes bibliotecas, conforme definido no `requirements.txt`:

```
# Framework da Interface Web
streamlit==1.50.0

# Frameworks principais do LangChain
langchain==1.0.2
langchain-core==1.0.1
langgraph==1.0.1

# M√≥dulos e integra√ß√µes do LangChain
langchain-community==0.4
langchain-chroma==1.0.0
langchain-google-genai==3.0.0
langchain-huggingface==1.0.0
langchain-text-splitters==1.0.0

# Modelos de Embedding e Re-Ranking
sentence-transformers==5.1.2

# Carregamento de PDF (requerido pelo PyMuPDFLoader)
PyMuPDF==1.26.5

# Utilit√°rios
python-dotenv==1.1.1
tqdm==4.67.1
```

-----

## 1\. Instala√ß√£o e Configura√ß√£o

Siga estes passos para configurar o ambiente e executar a solu√ß√£o.

### 1.1. Pr√©-requisitos

  * **Python 3.10+** (Recomendado o uso de um ambiente virtual `venv` ou `conda`).
  * **Chave de API do Google:** Necess√°ria para usar o modelo Gemini. Obtenha a sua no [Google AI Studio](https://aistudio.google.com/app/apikey).

### 1.2. Cria√ß√£o do Ambiente Virtual (Recomendado)

Abra seu terminal na pasta raiz do projeto. Escolha a op√ß√£o (`venv` ou `conda`) de sua prefer√™ncia.

-----

**Op√ß√£o A: Usando `venv` (Padr√£o do Python)**

```bash
# 1. Crie o ambiente (usando o nome 'rag_solution')
python -m venv rag_solution

# 2. Ative o ambiente
# Windows
.\rag_solution\Scripts\activate
# macOS/Linux
source rag_solution/bin/activate
```

-----

**Op√ß√£o B: Usando `conda` (Anaconda)**

```bash
# 1. Crie o ambiente (usando o nome 'rag_solution' e especificando Python 3.10+)
conda create -n rag_solution python=3.10

# 2. Ative o ambiente
conda activate rag_solution
```

### 1.3. Instala√ß√£o das Depend√™ncias

Com o ambiente virtual (`rag_solution`) ativo, instale todas as bibliotecas listadas no `requirements.txt`:

```bash
pip install -r requirements.txt
```

### 1.4. Configura√ß√£o da Chave de API

1.  Na pasta raiz do projeto, crie um arquivo chamado `.env`.

2.  Adicione sua chave de API do Google Gemini a este arquivo:

    ```ini
    # .env
    # Substitua "SUA_CHAVE_AQUI" pela sua chave de API
    GEMINI_API_KEY="SUA_CHAVE_AQUI"
    ```

-----

## 2\. Como Executar a Solu√ß√£o (Produ√ß√£o)

Siga a sequ√™ncia abaixo para preparar e iniciar o chatbot principal.

### Passo 1: Adicionar Documentos

Coloque os arquivos `.pdf` que servir√£o como base de conhecimento dentro da pasta `/docs`.

### Passo 2: Inicializar o Banco de Dados do Hist√≥rico

Execute este comando **uma √∫nica vez** para criar a pasta `/database` e o arquivo `chat_solution.db` com todas as tabelas (produ√ß√£o e avalia√ß√£o).

```bash
python database.py
```

**(Importante:** Se voc√™ alterar a estrutura das tabelas no `database.py` no futuro, precisar√° excluir o arquivo `chat_solution.db` e executar este comando novamente).

### Passo 3: Ingerir os Documentos (Criar/Atualizar Banco Vetorial)

Este script processa os PDFs da pasta `/docs`, limpa os rodap√©s, divide em chunks, gera os embeddings e salva/sobrescreve o banco de dados vetorial na pasta `/vector_db`.

```bash
python ingest.py
```

**(Importante:** Execute este script sempre que adicionar, remover ou modificar os arquivos PDF na pasta `/docs`.)

### Passo 4: Iniciar a Aplica√ß√£o do Chatbot

Este comando inicia o servidor Streamlit para a interface principal do chatbot.

```bash
streamlit run app.py
```

Aguarde o carregamento dos modelos. O aplicativo ser√° aberto automaticamente no seu navegador (geralmente `http://localhost:8501`).

-----

## 3\. Su√≠te de Avalia√ß√£o e Auditoria (Execu√ß√£o)

O projeto inclui tr√™s aplica√ß√µes web (Streamlit) dedicadas para valida√ß√£o e auditoria. Execute-as em terminais separados conforme necess√°rio.

### 3.1. `validate_vector_db.py`: Coleta de Avalia√ß√£o Manual

Esta ferramenta permite **criar** os dados de avalia√ß√£o. Voc√™ testa queries, avalia os resultados (marcando checkboxes e radio buttons) e salva as m√©tricas no banco de dados.

**Como Executar:**

```bash
streamlit run validate_vector_db.py
```

**Funcionalidades:**

  * **Testar Busca (S√ì Vetorial):** Testa a busca vetorial pura.
  * **Testar Busca (COM Re-Ranking):** Testa o pipeline completo com re-ranking.
  * **Formul√°rio de Avalia√ß√£o:** Permite ao avaliador calcular HR, MRR e P@K para cada query.
  * **Listar/Exportar Chunks:** Ferramentas de utilidade para inspecionar o ChromaDB.

### 3.2. `validate_evaluation.py`: Dashboard de M√©tricas de Avalia√ß√£o

Esta ferramenta permite **analisar** os dados coletados pela ferramenta anterior. √â o seu principal dashboard para medir a performance do RAG.

**Como Executar:**

```bash
streamlit run validate_evaluation.py
```

**Funcionalidades:**

  * **Resumo das M√©tricas:** Compara o desempenho (HR, MRR, P@K) de "Vetorial" vs. "Re-Ranking".
  * **Listar Avalia√ß√µes Detalhada:** Permite ver cada teste individual que foi salvo.
  * **Exportar Avalia√ß√µes (XML):** Cria um backup ou arquivo de compartilhamento com todos os dados de avalia√ß√£o.
  * **Importar Avalia√ß√µes (XML):** Permite consolidar dados de avalia√ß√£o de outros membros da equipe, ignorando duplicatas.

### 3.3. `validate_history_db.py`: Dashboard de Auditoria de Produ√ß√£o

Esta ferramenta permite analisar o **uso real** do seu chatbot (`app.py`), lendo o hist√≥rico de produ√ß√£o.

**Como Executar:**

```bash
streamlit run validate_history_db.py
```

**Funcionalidades:**

  * **Listar Todas as Sess√µes:** Mostra um resumo de todas as conversas (sess√µes).
  * **Buscar por Sess√£o:** Permite visualizar a transcri√ß√£o completa de uma conversa espec√≠fica.
  * **Ver Avalia√ß√µes (Feedback):** Lista todos os feedbacks (üëç/üëé) dados pelos usu√°rios finais, mostrando a mensagem associada.
  * **Exportar Hist√≥rico para CSV:** Gera um arquivo CSV com todos os dados da tabela `chat_history`.

-----

## 4\. Fluxo de Trabalho: Coletando M√©tricas (Criando o Gabarito)

A parte mais importante da avalia√ß√£o de um RAG √© a cria√ß√£o de um "gabarito" (dataset de *ground truth*) de alta qualidade. Este gabarito consiste em um conjunto de perguntas-padr√£o (queries) e o julgamento humano sobre os resultados que o sistema retorna para elas.

O dashboard `validate_evaluation.py` s√≥ √© √∫til ap√≥s a coleta desses dados, que √© feita com o `validate_vector_db.py`.

### Procedimento de Coleta

Para construir um gabarito robusto para comparar "Vetorial" vs. "Re-Ranking", o avaliador humano deve seguir estes passos:

1.  **Executar a Ferramenta:** Inicie a ferramenta de coleta de avalia√ß√£o.
    ```bash
    streamlit run validate_vector_db.py
    ```
2.  **Preparar a Query:** Tenha uma pergunta de teste em mente (ex: "Quais os descontos para pagamento √† vista?").
3.  **Testar o Modo 1 (Vetorial):** Selecione "Testar Busca (S√ì Vetorial)" e execute a busca. O sistema exibir√° os **K\_FINAL** (ex: 3) resultados da busca vetorial pura.
4.  **Realizar o Julgamento (Gabarito):**
      * **Checkboxes (Hit Rate / Precis√£o@K):** O avaliador deve ler a query e marcar *todos* os chunks que, em sua opini√£o, s√£o relevantes para responder √† pergunta.
      * **Radio Buttons (MRR):** O avaliador deve selecionar o *√∫nico e melhor* chunk que responde √† pergunta. Se nenhum for bom, deve selecionar "Nenhuma (MRR = 0)".
5.  **Salvar a Avalia√ß√£o:** Clique em "Salvar Avalia√ß√£o". O sistema ir√° calcular as tr√™s m√©tricas (HR, MRR, P@K) com base nos seus cliques e salvar√° essa rodada no banco de dados.
6.  **Testar o Modo 2 (Re-Ranking):** Selecione "Testar Busca (COM Re-Ranking)". Insira a **mesma query** do Passo 2. O sistema exibir√° os K\_FINAL resultados *ap√≥s* o processo de re-ranking.
7.  **Realizar o Julgamento (Gabarito):** Repita o Passo 4, julgando este novo conjunto de resultados.
8.  **Salvar a Avalia√ß√£o:** Clique em "Salvar Avalia√ß√£o" novamente.
9.  **Repetir:** Volte ao Passo 2 com uma nova pergunta.

Ao repetir esse processo para dezenas de queries, voc√™ construir√° um dataset rico que permitir√° ao `validate_evaluation.py` calcular estatisticamente qual dos dois m√©todos √© superior.

### Exemplos de C√°lculo de M√©tricas (K=3)

Assuma que o sistema est√° configurado para retornar **K=3** resultados.

-----

**Exemplo 1: Resultado "Perfeito"**

  * **Query:** "O que √© transa√ß√£o tribut√°ria?"
  * **Resultados:** O sistema retorna 3 chunks.
  * **Julgamento do Avaliador:**
      * **Checkboxes:** Chunk 1 (define o termo) e Chunk 3 (d√° um exemplo) s√£o marcados como relevantes.
      * **Radio:** O Chunk 1 √© selecionado como a "MELHOR" resposta.
  * **M√©tricas Salvas:**
      * `hit_rate_eval` = **1** (porque *pelo menos um* foi marcado)
      * `mrr_eval` = **1.0** (porque o melhor estava na posi√ß√£o 1; `1/1`)
      * `precision_at_k_eval` = **0.66** (porque *dois* foram marcados; `2/3`)

-----

**Exemplo 2: Resultado "Bom, mas Mal Ranqueado"**

  * **Query:** "Quais os descontos para pagamento √† vista?"
  * **Resultados:** O sistema retorna 3 chunks. O Chunk 1 fala sobre parcelamento, o Chunk 2 fala sobre juros, e o Chunk 3 fala sobre desconto √† vista.
  * **Julgamento do Avaliador:**
      * **Checkboxes:** Apenas o Chunk 3 √© marcado como relevante.
      * **Radio:** O Chunk 3 √© selecionado como a "MELHOR" resposta.
  * **M√©tricas Salvas:**
      * `hit_rate_eval` = **1** (porque *pelo menos um* foi marcado)
      * `mrr_eval` = **0.33** (porque o melhor estava na posi√ß√£o 3; `1/3`)
      * `precision_at_k_eval` = **0.33** (porque *um* foi marcado; `1/3`)

-----

**Exemplo 3: Resultado "Falha Total (Miss)"**

  * **Query:** "Qual o CNPJ da Procuradoria?" (Assumindo que esta informa√ß√£o n√£o est√° nos documentos)
  * **Resultados:** O sistema retorna 3 chunks que mencionam "Procuradoria", mas nenhum cont√©m o CNPJ.
  * **Julgamento do Avaliador:**
      * **Checkboxes:** Nenhum chunk √© marcado.
      * **Radio:** A op√ß√£o "Nenhuma (MRR = 0)" √© selecionada.
  * **M√©tricas Salvas:**
      * `hit_rate_eval` = **0** (porque *nenhum* foi marcado)
      * `mrr_eval` = **0.0** (porque "Nenhuma" foi selecionada)
      * `precision_at_k_eval` = **0.0** (porque *zero* foram marcados; `0/3`)

-----

## 5\. Estrutura do Projeto

```
/rag_chatbot
|
|-- .env                     # (Voc√™ cria) Armazena a GEMINI_API_KEY
|-- config.py                # Configura√ß√µes centrais (caminhos, nomes de modelos, etc.)
|-- requirements.txt         # Depend√™ncias Python
|
|-- app.py                   # Aplica√ß√£o principal do Chatbot (Streamlit UI)
|-- rag_chain.py             # L√≥gica principal do RAG (LangGraph, LLM, Hist√≥rico)
|-- vector_retriever.py      # Classe para busca vetorial e re-ranking (Chroma + CrossEncoder)
|-- database.py              # Gerenciamento do schema do banco de dados SQLite (todas as tabelas)
|
|-- ingest.py                # Script para processar PDFs e criar/atualizar o VectorDB (Chroma)
|
|-- validate_vector_db.py    # Ferramenta de Coleta de Avalia√ß√£o (Streamlit UI)
|-- validate_evaluation.py   # Ferramenta de An√°lise de M√©tricas (Streamlit UI)
|-- validate_history_db.py   # Ferramenta de Auditoria de Produ√ß√£o (Streamlit UI)
|
|-- /docs/                   # Pasta para colocar os arquivos .pdf de entrada
|-- /database/               # Pasta onde o banco SQLite (chat_solution.db) √© salvo
|   |-- chat_solution.db     # Arquivo do banco SQLite
|-- /vector_db/              # Pasta onde o ChromaDB (embeddings) √© salvo
|
|-- README.md                # Este arquivo
```

-----

## 6\. Nota sobre o Desenvolvimento e Colabora√ß√£o com IA

Este projeto representa um fluxo de trabalho moderno de desenvolvimento assistido por Intelig√™ncia Artificial.

A arquitetura do sistema, a defini√ß√£o de todas as regras de neg√≥cio, os requisitos funcionais, o fluxo de dados e o processo de depura√ß√£o e valida√ß√£o (QA) foram concebidos e dirigidos pelo desenvolvedor humano.

A gera√ß√£o da sintaxe de c√≥digo (Python, Streamlit, SQL, etc.), a documenta√ß√£o inicial (*docstrings*) e as refatora√ß√µes de c√≥digo foram executadas em colabora√ß√£o direta com o **Google Gemini**, que atuou como um assistente de programa√ß√£o (*pair programmer*). O fluxo de trabalho consistiu no desenvolvedor solicitando as funcionalidades em linguagem natural e, em seguida, validando, testando e corrigindo o c√≥digo gerado pelo LLM.